{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLgHxIifMcqE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "\n",
        "import numpy as np\n",
        "import gudhi\n",
        "from gudhi.wasserstein import wasserstein_distance\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import ot\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIEoN6IsMcqG"
      },
      "outputs": [],
      "source": [
        "# Define constants\n",
        "num_train_samples = 1   # always 1 because we are using iterativ learning\n",
        "cloud = 500             # points in point cloud\n",
        "pts = 3                 # xyz coordinates\n",
        "channels = 1            # no color channels\n",
        "\n",
        "output_classes = cloud*pts\n",
        "\n",
        "# load input and target models which have already been normalized\n",
        "loaded_array = np.load(\"npy/input_norm.npy\")\n",
        "loaded_array2 = np.load(\"npy/target_norm.npy\")\n",
        "\n",
        "# subsampled_arr = loaded_array[:500,:]\n",
        "# subsampled_arr2 = loaded_array2[:500,:]\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train_tensor = torch.FloatTensor(loaded_array)\n",
        "targets_train_tensor = torch.FloatTensor(loaded_array2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfhsysXpMcqJ"
      },
      "outputs": [],
      "source": [
        "class SharedMLP(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(SharedMLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(in_channels, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "class PointNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PointNet, self).__init__()\n",
        "        self.shared_mlp = SharedMLP(3, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Reshape to (n, 3) to apply shared MLP\n",
        "        x = x.view(-1, 3)\n",
        "\n",
        "        # Apply shared MLP\n",
        "        x = self.shared_mlp(x)\n",
        "\n",
        "        # Reshape back to (n, 3)\n",
        "        x = x.view(-1, 3)\n",
        "\n",
        "        # normalize output points\n",
        "        # max_vals, _ = torch.abs(x).max(dim=0)\n",
        "        # x = 2*x / max_vals\n",
        "\n",
        "        return x\n",
        "\n",
        "model = PointNet()\n",
        "optimizer = optim.Adam(model.parameters(), lr=.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLhIIMtcMcqK"
      },
      "outputs": [],
      "source": [
        "def preventCollapse(inputs,points, targets, epoch, delta=0.2, epsilon=1e-6, alpha=0.3, beta=0.7):\n",
        "    pairwise_distances = torch.cdist(points, points)\n",
        "\n",
        "    # Set diagonal elements of the mask to False\n",
        "    mask = torch.ones_like(pairwise_distances, dtype=torch.bool)\n",
        "    mask[torch.arange(points.size(0)), torch.arange(points.size(0))] = False\n",
        "\n",
        "    # Mask where distances are lesser than delta\n",
        "    mask &= pairwise_distances < delta\n",
        "    num_terms = mask.sum()\n",
        "\n",
        "    # Calculate sum of distances where distance is lesser than delta\n",
        "    sum_distances = torch.sum(1/pairwise_distances[mask])\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = sum_distances / (num_terms + 1e-6)  # Avoid division by zero\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print('COLLAPSE LOSS\\t:', loss)\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YA6cZEZYMcqL"
      },
      "outputs": [],
      "source": [
        "def geoloss(inpts, pts, pts2, idx):\n",
        "    distances_1to2 = torch.cdist(pts, inpts, p=2)  # Shape: (n, m)\n",
        "    distances_2to1 = torch.cdist(inpts, pts, p=2)  # Shape: (m, n)\n",
        "\n",
        "    # Find minimum distances for each point in both directions\n",
        "    min_distances_1to2 = torch.min(distances_1to2, dim=1).values  # Shape: (n,)\n",
        "    min_distances_2to1 = torch.min(distances_2to1, dim=1).values  # Shape: (m,)\n",
        "\n",
        "    # Compute Chamfer distance (mean of minimum distances in both directions)\n",
        "    chamfer_dist = torch.mean(min_distances_1to2) + torch.mean(min_distances_2to1)\n",
        "\n",
        "    if idx % 10 == 0:\n",
        "        print('GEOMETRIC LOSS\\t:', chamfer_dist)\n",
        "    return chamfer_dist\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0c2VNhQMcqL"
      },
      "outputs": [],
      "source": [
        "def topoloss(inpts,pts,pts2,idx):\n",
        "    # Increasing minimum persistence after a few iterations so that initially diagram contains points\n",
        "    max_length_rips = 0.3\n",
        "    min_per = 0.01\n",
        "    if(idx > 40):\n",
        "        max_length_rips = 0.3\n",
        "        min_per = 0.04\n",
        "\n",
        "    # Create rips complex using point cloud with 0.3 max edge length which is suitable for the normalized point cloud\n",
        "    rips = gudhi.RipsComplex(points=pts, max_edge_length=max_length_rips)\n",
        "    rips2 = gudhi.RipsComplex(points=pts2, max_edge_length=0.3)\n",
        "\n",
        "    # Create simplex tree from rips complex and compute persistence\n",
        "    st = rips.create_simplex_tree(max_dimension=2)\n",
        "    st.compute_persistence(min_persistence=min_per)\n",
        "    st2 = rips2.create_simplex_tree(max_dimension=2)\n",
        "    st2.compute_persistence(min_persistence=.04)\n",
        "\n",
        "    # find reverse mapping of points in the persistence diagram\n",
        "    i = st.flag_persistence_generators()\n",
        "    j = st2.flag_persistence_generators()\n",
        "\n",
        "    # It is better to avoid this condition completely\n",
        "    if ( len(i[1]) == 0 or len(j[1])==0 ):\n",
        "        i1 = torch.tensor(i[0])  # pytorch sometimes interprets it as a tuple otherwise\n",
        "        j1 = torch.tensor(j[0])  # pytorch sometimes interprets it as a tuple otherwise\n",
        "        diag1 = torch.norm(pts[i1[:, (0, 0)]] - pts[i1[:, (1, 2)]], dim=-1)\n",
        "        diag2 = torch.norm(pts2[j1[:, (0, 0)]] - pts2[j1[:, (1, 2)]], dim=-1)\n",
        "        return wasserstein_distance(diag1, diag2, order=2, keep_essential_parts=False, enable_autodiff=True)\n",
        "\n",
        "    i1 = torch.tensor(i[1][0])\n",
        "    j1 = torch.tensor(j[1][0])\n",
        "\n",
        "    # Same as the finite part of st.persistence_intervals_in_dimension(1), but differentiable\n",
        "    diag1 = torch.norm(pts[i1[:, (0, 2)]] - pts[i1[:, (1, 3)]], dim=-1)\n",
        "    diag2 = torch.norm(pts2[j1[:, (0, 2)]] - pts2[j1[:, (1, 3)]], dim=-1)\n",
        "\n",
        "    perstot1 = wasserstein_distance(diag1, diag2, order=2, keep_essential_parts=False, enable_autodiff=True)\n",
        "\n",
        "    # For visualization purposes\n",
        "    b_points = pts[i1[:, (0, 2)]] # birth points\n",
        "    d_points = pts[i1[:, (1, 3)]] # death points\n",
        "    b_critical = b_points.view(b_points.shape[0]*b_points.shape[1], 3)\n",
        "    d_critical = d_points.view(d_points.shape[0]*d_points.shape[1], 3)\n",
        "\n",
        "    if(idx%10 == 0):\n",
        "\n",
        "        print('TOPO LOSS\\t:', perstot1)\n",
        "        P = pts.detach().numpy()\n",
        "\n",
        "        # Create a 3D scatter plot\n",
        "        fig = plt.figure()\n",
        "        ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "        b_critical = b_critical.detach().numpy()\n",
        "        d_critical = d_critical.detach().numpy()\n",
        "\n",
        "        ax.scatter(P[:, 0], P[:, 1], P[:, 2])\n",
        "        ax.scatter(d_critical[:, 0], d_critical[:, 1], d_critical[:, 2], color='yellow', s=20)\n",
        "        ax.scatter(b_critical[:, 0], b_critical[:, 1], b_critical[:, 2], color='red', s=20)\n",
        "\n",
        "        # Set labels and title for the plot\n",
        "        ax.set_xlabel('X Label')\n",
        "        ax.set_ylabel('Y Label')\n",
        "        ax.set_zlabel('Z Label')\n",
        "        ax.set_title('3D Scatter Plot of 3D Points', color=\"black\")\n",
        "        plt.show()\n",
        "\n",
        "    return perstot1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "qSIasKjCMcqM",
        "outputId": "bf653bef-7e7f-4969-c05b-2d54364a3213"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "inputs = X_train_tensor.to(device)\n",
        "targets = targets_train_tensor.to(device)\n",
        "\n",
        "# # For Threading\n",
        "# total_loss = 0\n",
        "# def execute_function_and_update_sum(func, inputs, outputs, targets,epoch):\n",
        "#     global total_loss\n",
        "#     result = func(inputs, outputs, targets,0)\n",
        "#     total_loss += result\n",
        "# duration_in_seconds = 3600\n",
        "# start_time = time.time()\n",
        "# epoch = 0\n",
        "\n",
        "\n",
        "num_epochs = 1000\n",
        "for epoch in range(num_epochs):\n",
        "    if(epoch%10 == 0):\n",
        "        clear_output(wait=True)\n",
        "        print(\"EPOCH:\", epoch)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(inputs)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    lr = 0.1 * (epoch)/100\n",
        "\n",
        "    lambda_geo = 0.6\n",
        "    lambda_topo = 0.3\n",
        "    lambda_collapse = 0.1\n",
        "\n",
        "    loss =  lambda_topo*topoloss(inputs, outputs, targets,epoch) + lambda_geo*geoloss(inputs, outputs, targets,epoch) + lambda_collapse*preventCollapse(inputs, outputs, targets,epoch, 0.05)\n",
        "\n",
        "    # # Threading\n",
        "    # total_loss = 0\n",
        "    # thread1 = threading.Thread(target=execute_function_and_update_sum, args=(topoloss,inputs, outputs, targets,epoch))\n",
        "    # thread2 = threading.Thread(target=execute_function_and_update_sum, args=(geoloss,inputs, outputs, targets,epoch))\n",
        "    # thread3 = threading.Thread(target=execute_function_and_update_sum, args=(preventCollapse,inputs, outputs, targets,epoch))\n",
        "    # thread1.start()\n",
        "    # thread2.start()\n",
        "    # thread3.start()\n",
        "    # thread1.join()\n",
        "    # thread2.join()\n",
        "    # thread3.join()\n",
        "    # print(\"Total Loss\\t:\", total_loss)\n",
        "\n",
        "    if (epoch%10 == 0):\n",
        "        print(\"Total Loss\\t:\", loss)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # # Threading\n",
        "    # epoch += 1\n",
        "    # if time.time() - start_time >= duration_in_seconds:\n",
        "    #     break\n",
        "\n",
        "print(\"Training Complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eCOSyIIMcqO"
      },
      "outputs": [],
      "source": [
        "# Final Output Model\n",
        "outputs = model(inputs)\n",
        "P = outputs.detach().numpy()\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(P[:, 0], P[:, 1], P[:, 2])\n",
        "ax.set_xlabel('X Label')\n",
        "ax.set_ylabel('Y Label')\n",
        "ax.set_zlabel('Z Label')\n",
        "ax.set_title('3D Scatter Plot of 3D Points')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKTCx-BnMcqP"
      },
      "outputs": [],
      "source": [
        "# Save npy and xyz file for visualization\n",
        "np.save('output_3d.npy', outputs.detach().numpy())\n",
        "xyz_file = 'output_3d.xyz'\n",
        "with open(xyz_file, 'w') as f:\n",
        "        # Write each point to the .xyz file\n",
        "        for point in outputs:\n",
        "            x, y, z = point\n",
        "            f.write(f\"{x} {y} {z}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKVIPFLMMcqN"
      },
      "outputs": [],
      "source": [
        "# Input model\n",
        "P = inputs.detach().numpy()\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(P[:, 0], P[:, 1], P[:, 2])\n",
        "ax.set_xlabel('X Label')\n",
        "ax.set_ylabel('Y Label')\n",
        "ax.set_zlabel('Z Label')\n",
        "ax.set_title('3D Scatter Plot of 3D Points')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "218_dPtxMcqP"
      },
      "outputs": [],
      "source": [
        "# Target topology model\n",
        "P = targets.detach().numpy()\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(P[:, 0], P[:, 1], P[:, 2])\n",
        "ax.set_xlabel('X Label')\n",
        "ax.set_ylabel('Y Label')\n",
        "ax.set_zlabel('Z Label')\n",
        "ax.set_title('3D Scatter Plot of 3D Points')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
